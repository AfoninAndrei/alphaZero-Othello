# alphaZero-Othello
Implementation of AlphaZero for the Othello game from scratch

## 📖 Learn More

Check out the full explanation of the project and training process in the blog post:  
👉 [From Zero to Banned: Make Othello AI at home](https://afoninandrei.github.io/general/2025/05/30/othelloZero.html)

## 🧠 Trained Models

You can download the latest pretrained models from the [final release](https://github.com/AfoninAndrei/alphaZero-Othello/releases/tag/final).

- [🔗 Big model](https://github.com/AfoninAndrei/alphaZero-Othello/releases/download/final/othello_policy_RL_big.pt)
- [🔗 Small model](https://github.com/AfoninAndrei/alphaZero-Othello/releases/download/final/othello_policy_RL_small.pt)

---

## 🎮 Play Against the MCTS Bot

To play against the trained AlphaZero-style MCTS bot, run:

### ▶️ Default (bot plays black, big model):
```bash
python play_othello.py
```

### ♟️ Small model + bot as white:
```bash
python play_othello.py --no-big-model --bot-player -1
```

---

## 📦 Datasets

The following datasets were used to train the AlphaZero and FastOthello models:

### 🔁 Replay Buffers (Reinforcement Learning)

- [🎯 Big model replay buffer](https://github.com/AfoninAndrei/alphaZero-Othello/releases/download/final/othello_replay_big_model.tar.gz)
  Contains training data generated by MCTS + self-play using the large AlphaZero network.

- [⚡ Small model replay buffer](https://github.com/AfoninAndrei/alphaZero-Othello/releases/download/final/othello_replay_small_model.tar.gz)
  Same format, but generated by a lighter, faster model for faster experimentation.

Each file is a `.pkl` file containing tuples of:
```python
(state: np.ndarray, policy_target: np.ndarray, value_target: float, version: int)
```

To extract:
```bash
tar -xzvf othello_replay_big_model.tar.gz
```

---

### 🧑‍🏫 Supervised Learning Dataset

- [📚 Expert move dataset (CSV)](https://github.com/AfoninAndrei/alphaZero-Othello/releases/download/final/othello_dataset.csv)

This CSV contains expert Othello positions with best moves, useful for supervised pretraining.

---
